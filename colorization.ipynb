{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"h0mMmGeVGwOM"},"source":["# !pip install torchvision scikit-image pillow==4.1.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eACcoo7AF1Zm","executionInfo":{"status":"ok","timestamp":1638879026137,"user_tz":-330,"elapsed":16851,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}},"outputId":"72e7cf47-7abd-4f30-e5f9-709735cc5090"},"source":["!pip install https://github.com/CellProfiling/HPA-Cell-Segmentation/archive/master.zip"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting https://github.com/CellProfiling/HPA-Cell-Segmentation/archive/master.zip\n","  Downloading https://github.com/CellProfiling/HPA-Cell-Segmentation/archive/master.zip\n","\u001b[K     - 17 kB 4.5 MB/s\n","\u001b[?25hCollecting pytorch_zoo@ https://github.com/haoxusci/pytorch_zoo/archive/master.zip\n","  Downloading https://github.com/haoxusci/pytorch_zoo/archive/master.zip\n","\u001b[K     \\ 131 kB 5.3 MB/s\n","\u001b[?25hRequirement already satisfied: scikit-image>=0.16.2 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (0.18.3)\n","Collecting imageio>=2.6.1\n","  Downloading imageio-2.13.2-py3-none-any.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 13.1 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (1.4.1)\n","Collecting opencv-python>=4.2.0.32\n","  Downloading opencv_python-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n","\u001b[K     |████████████████████████████████| 60.3 MB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=6.2.1 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (7.1.2)\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (1.10.0+cu111)\n","Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (0.11.1+cu111)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from hpacellseg==0.1.8) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio>=2.6.1->hpacellseg==0.1.8) (1.19.5)\n","Collecting pillow>=6.2.1\n","  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 41.6 MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (2.6.3)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (3.2.2)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.2->hpacellseg==0.1.8) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (3.0.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.2->hpacellseg==0.1.8) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->hpacellseg==0.1.8) (3.10.0.2)\n","Building wheels for collected packages: hpacellseg, pytorch-zoo\n","  Building wheel for hpacellseg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hpacellseg: filename=hpacellseg-0.1.8-py3-none-any.whl size=14962 sha256=c1b98113967f3a445a9ec9cceee3b8479a9efe837cc036320c23ac0aee7e0090\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-9o7gtiry/wheels/cd/d8/de/04ad08802d62537f8dffc89b6a7ce0a53c3d29ea6eae522ab1\n","  Building wheel for pytorch-zoo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytorch-zoo: filename=pytorch_zoo-0.0.0-py3-none-any.whl size=30138 sha256=3cc4dd74d69f320f36e23579cb0a01d4a2ef3c8f796337418bc3dc194a5c2afc\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-9o7gtiry/wheels/58/0e/c7/567928a140c7cb2533c59bdc81fded8fe720ea8caad1659d8c\n","Successfully built hpacellseg pytorch-zoo\n","Installing collected packages: pillow, imageio, pytorch-zoo, opencv-python, hpacellseg\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: imageio\n","    Found existing installation: imageio 2.4.1\n","    Uninstalling imageio-2.4.1:\n","      Successfully uninstalled imageio-2.4.1\n","  Attempting uninstall: opencv-python\n","    Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed hpacellseg-0.1.8 imageio-2.13.2 opencv-python-4.5.4.60 pillow-8.4.0 pytorch-zoo-0.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"vcVfcvuTGVaf","executionInfo":{"status":"ok","timestamp":1638879081955,"user_tz":-330,"elapsed":1370,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["# For plotting\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","# For conversion\n","from skimage.color import lab2rgb, rgb2lab, rgb2gray\n","from skimage import io\n","# For everything\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","# For our model\n","import torchvision\n","import torchvision.models as models\n","from torchvision import datasets, transforms\n","# For utilities\n","import os, shutil, time\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"FG9kJlb4GeDN","executionInfo":{"status":"ok","timestamp":1638879081956,"user_tz":-330,"elapsed":3,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["use_gpu = torch.cuda.is_available()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"cz8smSzPGd4l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638880167696,"user_tz":-330,"elapsed":1085743,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}},"outputId":"2d354ce2-0eb6-4f63-a122-641ac3d065aa"},"source":["!wget http://data.csail.mit.edu/places/places205/testSetPlaces205_resize.tar.gz\n","!tar -xzf testSetPlaces205_resize.tar.gz"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-12-07 12:11:22--  http://data.csail.mit.edu/places/places205/testSetPlaces205_resize.tar.gz\n","Resolving data.csail.mit.edu (data.csail.mit.edu)... 128.52.129.40\n","Connecting to data.csail.mit.edu (data.csail.mit.edu)|128.52.129.40|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2341250899 (2.2G) [application/octet-stream]\n","Saving to: ‘testSetPlaces205_resize.tar.gz.1’\n","\n","testSetPlaces205_re 100%[===================>]   2.18G  3.07MB/s    in 18m 5s  \n","\n","2021-12-07 12:29:27 (2.06 MB/s) - ‘testSetPlaces205_resize.tar.gz.1’ saved [2341250899/2341250899]\n","\n","\n","gzip: stdin: unexpected end of file\n","tar: Unexpected EOF in archive\n","tar: Unexpected EOF in archive\n","tar: Error is not recoverable: exiting now\n"]}]},{"cell_type":"code","metadata":{"id":"RiNN847rPJ8Y","executionInfo":{"status":"ok","timestamp":1638880197075,"user_tz":-330,"elapsed":29392,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["!tar -xzf /content/testSetPlaces205_resize.tar.gz.1"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"keYeJO0ZNW2w","executionInfo":{"status":"ok","timestamp":1638880198495,"user_tz":-330,"elapsed":1451,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["import os\n","import shutil\n","os.makedirs('images/train/class/', exist_ok=True) # 40,000 images\n","os.makedirs('images/val/class/', exist_ok=True)   #  1,000 images\n","for i, file in enumerate(os.listdir('testSet_resize')):\n","  if i < 1000: # first 1000 will be val\n","    shutil.move('testSet_resize/' + file, 'images/val/class/' + file)\n","  else: # others will be val\n","    shutil.move('testSet_resize/' + file, 'images/train/class/' + file)\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"hLBLuLWzOrFV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638880201567,"user_tz":-330,"elapsed":3078,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}},"outputId":"5a7a5229-c2d9-4d25-a74f-ce1a15a6d701"},"source":["len(os.listdir(\"/content/images/train/class\"))"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40000"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"3jqUOT4mH4UX","executionInfo":{"status":"ok","timestamp":1638887929262,"user_tz":-330,"elapsed":571,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["class ColorizationNet(nn.Module):\n","  def __init__(self, input_size=128):\n","    super(ColorizationNet, self).__init__()\n","\n","    MIDLEVEL_FEATURE_SIZE = 128\n","    resnet=models.resnet18(pretrained=True)\n","    resnet.conv1.weight=nn.Parameter(resnet.conv1.weight.sum(dim=1).unsqueeze(1))\n","    \n","    self.midlevel_resnet =nn.Sequential(*list(resnet.children())[0:6])\n","\n","    self.upsample = nn.Sequential(     \n","      nn.Conv2d(MIDLEVEL_FEATURE_SIZE, 128, kernel_size=3, stride=1, padding=1),\n","      nn.BatchNorm2d(128),\n","      nn.ReLU(),\n","      nn.Upsample(scale_factor=2),\n","      nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n","      nn.BatchNorm2d(64),\n","      nn.ReLU(),\n","      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n","      nn.BatchNorm2d(64),\n","      nn.ReLU(),\n","      nn.Upsample(scale_factor=2),\n","      nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n","      nn.BatchNorm2d(32),\n","      nn.ReLU(),\n","      nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1),\n","      nn.Upsample(scale_factor=2)\n","    )\n","\n","  def forward(self, input):\n","\n","    # Pass input through ResNet-gray to extract features\n","    midlevel_features = self.midlevel_resnet(input)\n","\n","    # Upsample to get colors\n","    output = self.upsample(midlevel_features)\n","    return output\n","\n","    "],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"keJFlB7NHql4","executionInfo":{"status":"ok","timestamp":1638887986754,"user_tz":-330,"elapsed":620,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["model=ColorizationNet()"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"NBUbxw4JKMSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638887987500,"user_tz":-330,"elapsed":3,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}},"outputId":"9fb4e3e4-13c9-4d41-9601-58970cd2b660"},"source":["model(torch.rand(1,1,224,224)).shape"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 2, 224, 224])"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"E_9QnXD5K8Ok","executionInfo":{"status":"ok","timestamp":1638880202132,"user_tz":-330,"elapsed":27,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["class GrayscaleImageFolder(datasets.ImageFolder):\n","  '''Custom images folder, which converts images to grayscale before loading'''\n","  def __getitem__(self, index):\n","    path, target = self.imgs[index]\n","    img = self.loader(path)\n","    if self.transform is not None:\n","      img_original = self.transform(img)\n","      img_original = np.asarray(img_original)\n","      img_lab = rgb2lab(img_original)\n","      img_lab = (img_lab + 128) / 255\n","      img_ab = img_lab[:, :, 1:3]\n","      img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()\n","      img_original = rgb2gray(img_original)\n","      img_original = torch.from_numpy(img_original).unsqueeze(0).float()\n","    if self.target_transform is not None:\n","      target = self.target_transform(target)\n","    return img_original, img_ab, target"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"4NwHtfO2LneG","executionInfo":{"status":"ok","timestamp":1638887994170,"user_tz":-330,"elapsed":522,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["train_transforms = transforms.Compose([transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip()])\n","train_imagefolder = GrayscaleImageFolder('images/train', train_transforms)\n","train_loader = torch.utils.data.DataLoader(train_imagefolder, batch_size=64, shuffle=True)\n"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"7JCFpoCPPpot","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638887995211,"user_tz":-330,"elapsed":3,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}},"outputId":"94ed46cb-8f00-4110-e02c-e150bfde7b1b"},"source":["len(train_loader)"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["625"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"yHKVrzcjLuW8","executionInfo":{"status":"ok","timestamp":1638880202134,"user_tz":-330,"elapsed":22,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["# class AverageMeter(object):\n","#   '''A handy class from the PyTorch ImageNet tutorial''' \n","#   def __init__(self):\n","#     self.reset()\n","#   def reset(self):\n","#     self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n","#   def update(self, val, n=1):\n","#     self.val = val\n","#     self.sum += val * n\n","#     self.count += n\n","#     self.avg = self.sum / self.count\n","\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"vBbUNfBja8T7","executionInfo":{"status":"ok","timestamp":1638880202135,"user_tz":-330,"elapsed":22,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["#out.de.shape"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"kLDg84GLbKO2","executionInfo":{"status":"ok","timestamp":1638880202136,"user_tz":-330,"elapsed":23,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["#input.shape()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHhBcauna1Gq","executionInfo":{"status":"ok","timestamp":1638880202136,"user_tz":-330,"elapsed":21,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["#plt.imshow(show_output(input.squeeze(0),out.squeeze(0).cpu()))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uq2KO_OOLz2U","executionInfo":{"status":"ok","timestamp":1638887935247,"user_tz":-330,"elapsed":469,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["def train(train_loader, model, criterion, optimizer, epoch):\n","  print('Starting training epoch {}'.format(epoch))\n","  model.train()\n","\n","  for i, (input_gray, input_ab, target) in enumerate(train_loader):\n","    \n","    if use_gpu: input_gray, input_ab, target = input_gray.cuda(), input_ab.cuda(), target.cuda()\n","\n","    output_ab = model(input_gray) \n","    loss = criterion(output_ab, input_ab) \n","    # losses.update(loss.item(), input_gray.size(0))\n","\n","    # Compute gradient and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Print model accuracy -- in the code below, val refers to value, not validation\n","    if i % 25 == 0:\n","      print('Epoch: [{0}][{1}/{2}]\\t'\n","            'Loss {loss:.4f} ({loss:.4f})\\t'.format(\n","              epoch, i, len(train_loader), loss=loss)) \n","\n","  print('Finished training epoch {}'.format(epoch))\n"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"oFwAJCFMPuBb","executionInfo":{"status":"ok","timestamp":1638880202138,"user_tz":-330,"elapsed":21,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["#from IPython.display import Image, display\n","#display(Image(filename='/content/images/val/class/000d91ee9907dc11ecb76a0d4dd54cec.jpg'))"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"pG6osZ32UqHj","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"error","timestamp":1638887947302,"user_tz":-330,"elapsed":465,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}},"outputId":"86e84b6d-d691-4662-905c-070b7eacb3db"},"source":["import cv2\n","from google.colab.patches import cv2_imshow\n","im=cv2.imread(\"/content/b&w.jpg\")\n","cv2_imshow(im)\n","\n","lab=rgb2lab(im)\n","cv2_imshow(lab)\n"],"execution_count":43,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-17f0567eb8d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/b&w.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrgb2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clip'"]}]},{"cell_type":"code","metadata":{"id":"MH96lQfhVO-E","executionInfo":{"status":"aborted","timestamp":1638880203484,"user_tz":-330,"elapsed":18,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["#lab.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GBOS5uChVLnk","executionInfo":{"status":"aborted","timestamp":1638880203487,"user_tz":-330,"elapsed":21,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["#im.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7EQmKAIPt_I","colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"status":"error","timestamp":1638880556786,"user_tz":-330,"elapsed":608,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}},"outputId":"527cd4c8-4ac5-4698-90ce-65c5f0f1bf44"},"source":["\n","if use_gpu: \n","  criterion = criterion.cuda()\n","  model = model.cuda()\n"],"execution_count":21,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-5b13702abf1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"]}]},{"cell_type":"code","metadata":{"id":"q4eSibW1QHoL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8595cd86-a277-4b72-c740-f5f076882637"},"source":["\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-6, weight_decay=0.0)\n","model=model.cuda()\n","\n","for epoch in range(10):\n","  # Train for one epoch, then validate\n","  train(train_loader, model, criterion, optimizer, epoch)\n","  # torch.save(model.state_dict(), 'checkpoints/model-epoch-{}-losses-{:.3f}.pth'.format(epoch+1,loss))\n"," "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting training epoch 0\n","Epoch: [0][0/625]\tLoss 0.5006 (0.5006)\t\n","Epoch: [0][25/625]\tLoss 0.4979 (0.4979)\t\n","Epoch: [0][50/625]\tLoss 0.4945 (0.4945)\t\n","Epoch: [0][75/625]\tLoss 0.4890 (0.4890)\t\n","Epoch: [0][100/625]\tLoss 0.4737 (0.4737)\t\n","Epoch: [0][125/625]\tLoss 0.4724 (0.4724)\t\n","Epoch: [0][150/625]\tLoss 0.4600 (0.4600)\t\n","Epoch: [0][175/625]\tLoss 0.4621 (0.4621)\t\n","Epoch: [0][200/625]\tLoss 0.4606 (0.4606)\t\n","Epoch: [0][225/625]\tLoss 0.4424 (0.4424)\t\n","Epoch: [0][250/625]\tLoss 0.4442 (0.4442)\t\n","Epoch: [0][275/625]\tLoss 0.4345 (0.4345)\t\n","Epoch: [0][300/625]\tLoss 0.4234 (0.4234)\t\n","Epoch: [0][325/625]\tLoss 0.4316 (0.4316)\t\n","Epoch: [0][350/625]\tLoss 0.4129 (0.4129)\t\n","Epoch: [0][375/625]\tLoss 0.4036 (0.4036)\t\n","Epoch: [0][400/625]\tLoss 0.3988 (0.3988)\t\n","Epoch: [0][425/625]\tLoss 0.3908 (0.3908)\t\n","Epoch: [0][450/625]\tLoss 0.3854 (0.3854)\t\n","Epoch: [0][475/625]\tLoss 0.3796 (0.3796)\t\n","Epoch: [0][500/625]\tLoss 0.3623 (0.3623)\t\n","Epoch: [0][525/625]\tLoss 0.3555 (0.3555)\t\n","Epoch: [0][550/625]\tLoss 0.3391 (0.3391)\t\n","Epoch: [0][575/625]\tLoss 0.3251 (0.3251)\t\n","Epoch: [0][600/625]\tLoss 0.3131 (0.3131)\t\n","Finished training epoch 0\n","Starting training epoch 1\n","Epoch: [1][0/625]\tLoss 0.3114 (0.3114)\t\n","Epoch: [1][25/625]\tLoss 0.2995 (0.2995)\t\n","Epoch: [1][50/625]\tLoss 0.2846 (0.2846)\t\n","Epoch: [1][75/625]\tLoss 0.2728 (0.2728)\t\n","Epoch: [1][100/625]\tLoss 0.2607 (0.2607)\t\n","Epoch: [1][125/625]\tLoss 0.2483 (0.2483)\t\n","Epoch: [1][150/625]\tLoss 0.2444 (0.2444)\t\n","Epoch: [1][175/625]\tLoss 0.2358 (0.2358)\t\n","Epoch: [1][200/625]\tLoss 0.2334 (0.2334)\t\n","Epoch: [1][225/625]\tLoss 0.2301 (0.2301)\t\n","Epoch: [1][250/625]\tLoss 0.2284 (0.2284)\t\n","Epoch: [1][275/625]\tLoss 0.2137 (0.2137)\t\n","Epoch: [1][300/625]\tLoss 0.2075 (0.2075)\t\n","Epoch: [1][325/625]\tLoss 0.1950 (0.1950)\t\n","Epoch: [1][350/625]\tLoss 0.1944 (0.1944)\t\n","Epoch: [1][375/625]\tLoss 0.1873 (0.1873)\t\n","Epoch: [1][400/625]\tLoss 0.1857 (0.1857)\t\n","Epoch: [1][425/625]\tLoss 0.1805 (0.1805)\t\n","Epoch: [1][450/625]\tLoss 0.1787 (0.1787)\t\n","Epoch: [1][475/625]\tLoss 0.1724 (0.1724)\t\n","Epoch: [1][500/625]\tLoss 0.1699 (0.1699)\t\n","Epoch: [1][525/625]\tLoss 0.1651 (0.1651)\t\n","Epoch: [1][550/625]\tLoss 0.1563 (0.1563)\t\n"]}]},{"cell_type":"code","metadata":{"id":"sdOO59ggQdU2","executionInfo":{"status":"ok","timestamp":1638887606442,"user_tz":-330,"elapsed":578,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["torch.save(model.state_dict(), 'model-final.pth')\n"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0E6fhi-QDlX","executionInfo":{"status":"ok","timestamp":1638887610710,"user_tz":-330,"elapsed":735,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}},"outputId":"42a57d34-1b99-4b10-9421-7c922b1caef2"},"source":["model.load_state_dict(torch.load(\"/content/model-final.pth\"))"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"KGhI9taOXm4V","colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"status":"error","timestamp":1638886369236,"user_tz":-330,"elapsed":554,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}},"outputId":"427363d7-7eb9-494e-ca62-ba7ddb136f0d"},"source":["torch.Tensor(rgb2gray(im)).unsqueeze(0).unsqueeze(0)\n"],"execution_count":24,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-49110946b616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb2gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2gray\u001b[0;34m(rgb)\u001b[0m\n\u001b[1;32m    767\u001b[0m     \"\"\"\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mrgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m         warn('The behavior of rgb2gray will change in scikit-image 0.19. '\n\u001b[1;32m    771\u001b[0m              \u001b[0;34m'Currently, rgb2gray allows 2D grayscale image to be passed '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'ndim'"]}]},{"cell_type":"code","metadata":{"id":"Y5YkAzp7kkmo"},"source":["def colorize(img_path, print_img=True):\n","    img = cv2.imread(img_path)\n","    img = cv2.resize(img, (224, 224))\n","    grayscale_input = torch.Tensor(rgb2gray(img))\n","    ab_input = model(grayscale_input.unsqueeze(0).unsqueeze(0)).squeeze(0)\n","    predicted = show_output(grayscale_input.unsqueeze(0), ab_input)\n","    if print_img:\n","        plt.imshow(predicted)\n","    return predicted\n","def show_output(grayscale_input, ab_input):\n","    '''Show/save rgb image from grayscale and ab channels\n","       Input save_path in the form {'grayscale': '/path/', 'colorized': '/path/'}'''\n","    color_image = torch.cat((grayscale_input, ab_input), 0).detach().numpy()  # combine channels\n","    color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n","    color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n","    color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n","    color_image = lab2rgb(color_image.astype(np.float64))\n","    grayscale_input = grayscale_input.squeeze().numpy()\n","    # plt.imshow(grayscale_input)\n","    # plt.imshow(color_image)\n","    return color_image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4EAeMSeKVexo","executionInfo":{"status":"ok","timestamp":1638887887979,"user_tz":-330,"elapsed":537,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}}},"source":["model=torch.load(\"/content/model-final.pth\")\n","#model=ColorizationNet().cuda()\n","#model.load_state_dict(torch.load(\"/content/model-final.pth\"))"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"zHhIZPzolMb-","executionInfo":{"status":"error","timestamp":1638875508735,"user_tz":-330,"elapsed":677,"user":{"displayName":"Abhijnan Bajpai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjeTVhu2-nSLoFUQqG4ktaSrXuyGKlmfM1tNWfACcA=s64","userId":"09942308265650688449"}},"outputId":"0b66d1d5-1407-470f-e7c8-3024c62aeecb"},"source":["out = colorize(\"/content/b&w.jpg\")\n","print(out)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-17b72c8aba89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/b&w.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-e54b408a006d>\u001b[0m in \u001b[0;36mcolorize\u001b[0;34m(img_path, print_img)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgrayscale_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb2gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mab_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrayscale_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrayscale_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mab_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprint_img\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-6441ff731b6e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Pass input through ResNet-gray to extract features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmidlevel_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidlevel_resnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Upsample to get colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"]}]},{"cell_type":"code","metadata":{"id":"BEb7ui4HVoYV"},"source":["input=torch.Tensor(rgb2gray(im)).unsqueeze(0).unsqueeze(0).cuda()\n","out=model(input)\n","#out=(torch.cat([out,input],dim=1).squeeze(0)).permute([1,2,0])\n","# plt.imshow(out.detach().numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"THj6q1tXZnwg","colab":{"base_uri":"https://localhost:8080/","height":165},"executionInfo":{"status":"error","timestamp":1638872245902,"user_tz":-330,"elapsed":361,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}},"outputId":"e1750025-4507-4ffe-b15e-e0d72e14f96f"},"source":["out=(torch.cat([out,input],dim=1).squeeze(0)).permute([1,2,0])\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-b42bc915e681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 2976 but got size 2975 for tensor number 1 in the list."]}]},{"cell_type":"code","metadata":{"id":"aYLw29JOZiAD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638872231882,"user_tz":-330,"elapsed":381,"user":{"displayName":"mini project","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02651307831995742286"}},"outputId":"eaa3ec5d-9df8-409e-b2fc-0bd0f21000e1"},"source":["print(input.shape)\n","out.shape"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1, 2975, 2082])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 2, 2976, 2088])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"4wSqzMgJV15A"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","# shutil.copy(\"/content/model-epoch-2.pth\",\"/content/drive/MyDrive/Datasets/Models/Image Colorizer\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LioOcsPWWOK3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vhpu0OANhtNB"},"source":["def show_output(grayscale_input, ab_input):\n","  '''Show/save rgb image from grayscale and ab channels\n","     Input save_path in the form {'grayscale': '/path/', 'colorized': '/path/'}'''\n","  color_image = torch.cat((grayscale_input, ab_input), 0).detach().numpy() # combine channels\n","  color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n","  color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n","  color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128   \n","  color_image = lab2rgb(color_image.astype(np.float64))\n","  grayscale_input = grayscale_input.squeeze().numpy()\n","  # plt.imshow(grayscale_input)\n","  # plt.imshow(color_image)\n","  return color_image\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gG55jXoSiZK5"},"source":["model=model.cpu()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wm_mopGUXcrn"},"source":["def colorize(img_path,print_img=True):\n","    grayscale_input= torch.Tensor(rgb2gray(cv2.imread(img_path)))\n","    ab_input=model(grayscale_input.unsqueeze(0).unsqueeze(0)).squeeze(0)\n","    predicted=show_output(grayscale_input.unsqueeze(0), ab_input)\n","    plt.imshow(predicted)\n","    return predicted"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4eNbIZ-8hxca"},"source":["colorize(\"/content/images/val/class/00bd27e623e062785c317ef58ad6e7c0.jpg\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZSbe58aw0ain"},"source":[""],"execution_count":null,"outputs":[]}]}